# ğŸš€ Agentic RAG with Pinecone â€” End-to-End Pipeline

This repository contains a modular workflow to build a **production-ready Agentic RAG system** using **Pinecone**, **Amazon Bedrock**, and **vector database pipelines**.  
Each stage of the pipeline is implemented via a dedicated notebook, enabling a clear and scalable development flow.

---

## ğŸ“‚ Project Structure

```bash
ğŸ“¦ agentic-rag-pinecone/
â”œâ”€â”€ 1_data_loading_pipeline.ipynb      # Load data, chunk, embed & upload vectors to Pinecone
â”œâ”€â”€ 2_data_query_pipeline.ipynb        # Query Pinecone & generate a basic RAG response
â”œâ”€â”€ 3_agentic_rag.ipynb                # Agentic RAG â€” use tools & multi-step reasoning
â””â”€â”€ 4_clean_up.ipynb                   # Delete resources & clean up Pinecone/AWS setup

ğŸ“Œ Project Overview
This project demonstrates how to build an Agentic Retrieval-Augmented Generation (RAG) workflow using Pinecone + AWS Bedrock.
It teaches how to:
âœ” Load and process documents
âœ” Create & query vector embeddings
âœ” Implement multi-step Agentic RAG
âœ” Clean up resources programmatically
The workflow is modular and scalable â€” ideal for experimentation, workshops, and production prototyping.
________________________________________
ğŸ”§ Installation
# Create environment
conda create -n rag_env python=3.10 -y
conda activate rag_env

# Install dependencies
pip install -r requirements.txt
ğŸ’¡ If requirements.txt is missing, install the libraries directly from the notebooks (pip install sections inside each notebook).
________________________________________
ğŸ”‘ Environment Setup
Create a .env file with your credentials:
PINECONE_API_KEY=your_key_here
AWS_ACCESS_KEY=...
AWS_SECRET_KEY=...
AWS_REGION=...
Ensure these are not committed to Git. Add them to .gitignore.
________________________________________
ğŸ“˜ Notebook Workflow
ğŸ§© 1ï¸âƒ£ Module â€” Data Loading
Notebook: 1_data_loading_pipeline.ipynb
â€¢	Chunk & embed documents
â€¢	Create Pinecone index
â€¢	Upload vectors to database
________________________________________
ğŸ” 2ï¸âƒ£ Module â€” Data Query + RAG
Notebook: 2_data_query_pipeline.ipynb
â€¢	Perform semantic search via Pinecone
â€¢	Generate a basic RAG response
â€¢	Interface with AWS Bedrock for LLM inference
________________________________________
ğŸ§  3ï¸âƒ£ Module â€” Agentic RAG
Notebook: 3_agentic_rag.ipynb
Implements agent-style reasoning & tool usage:
â€¢	Tool selection and planning
â€¢	Query re-ranking & retrieval enhancement
â€¢	Multi-step reasoning based on context
________________________________________
ğŸ§¹ 4ï¸âƒ£ Module â€” Clean Up
Notebook: 4_clean_up.ipynb
â€¢	Delete Pinecone index
â€¢	Release AWS resources
â€¢	Ensure no unwanted cloud resources remain
________________________________________
ğŸ“ˆ Future Enhancements
You can extend this project with:
â€¢	ğŸ“Š Evaluation metrics (nDCG, MRR, recall@k)
â€¢	ğŸ” Hybrid search (text + metadata)
â€¢	ğŸ§ª RAG evaluation benchmarks
â€¢	ğŸ–¥ï¸ Streamlit or Gradio UI
â€¢	ğŸ§  Fine-tuned reasoning agents

